# ğŸ¤– Quick Start: AI Chat in Boring Notch

## What's New?

Your Boring Notch now has **built-in AI chat** powered by Ollama! Chat with AI models directly from the notch interface.

## 5-Minute Setup

### Step 1: Install Ollama

```bash
# Visit https://ollama.ai and download, or use Homebrew:
brew install ollama
```

### Step 2: Download a Model

```bash
# Start with Llama 2 (recommended):
ollama pull llama2

# Or try others:
ollama pull mistral    # Smaller, faster
ollama pull codellama  # Great for coding
ollama pull phi        # Tiny and fast
```

### Step 3: Start Chatting!

**Three ways to open AI Chat:**

1. âŒ¨ï¸ Press `âŒ˜â‡§J` (Command + Shift + J)
2. ğŸ–±ï¸ Hold `âŒ¥ Option` and click the notch
3. âš™ï¸ Open from Settings â†’ AI Chat

## That's It!

The AI chat will:
- âœ… Auto-detect Ollama running on your Mac
- âœ… Show all installed models
- âœ… Stream responses in real-time
- âœ… Keep your chat history

## Tips

- **Switch models**: Click the slider icon in the chat header
- **Clear history**: Click the trash icon
- **Change server**: Settings â†’ AI Chat â†’ Server URL
- **Privacy**: Everything runs locally, no data leaves your Mac!

## Troubleshooting

**"Ollama not connected"**
```bash
# Make sure Ollama is running:
ollama serve

# Or check status:
curl http://localhost:11434/api/tags
```

**"No models available"**
```bash
# Install at least one model:
ollama pull llama2
```

## What Changed?

- âŒ **Removed**: Old Python-based JABA integration
- âœ… **Added**: Native Swift + Ollama integration
- âœ… **Result**: Faster, simpler, more reliable!

---

**Enjoy chatting with AI right in your notch! ğŸš€**
